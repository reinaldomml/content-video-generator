#!/usr/bin/env python3
"""
Gerador de Ebook a partir de V√≠deos do YouTube

Este script automatiza a cria√ß√£o de ebooks a partir do conte√∫do de v√≠deos do YouTube.
Ele baixa o √°udio, transcreve usando a API da OpenAI, processa o conte√∫do com IA
para criar um ebook estruturado e gera um PDF formatado.
"""

import json
import os
import sys
import tempfile
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional

import openai
import yt_dlp
from jinja2 import Environment, FileSystemLoader
from weasyprint import CSS, HTML

# Importa todas as configura√ß√µes do projeto
from config import *
from prompts.system_prompt_ebook import SYSTEM_PROMPT_EBOOK
from prompts.user_prompt_ebook import get_user_prompt_ebook

# Configura logging usando as configura√ß√µes centralizadas
logger = setup_logging()

# Configura√ß√£o da API OpenAI
openai.api_key = OPENAI_API_KEY


class YouTubeEbookGenerator:
    """Classe principal para gerar ebooks a partir de v√≠deos do YouTube."""

    def __init__(self, output_dir: str = None):
        """
        Inicializa o gerador de ebooks.

        Args:
            output_dir: Diret√≥rio para salvar os arquivos de sa√≠da (usa DEFAULT_OUTPUT_DIR se None)
        """
        self.output_dir = Path(output_dir or DEFAULT_OUTPUT_DIR)
        self.output_dir.mkdir(exist_ok=True)
        self.temp_dir = None
        self.total_cost_usd = 0.0

        # Verifica se a API key est√° configurada
        if not openai.api_key:
            raise ValueError('OPENAI_API_KEY n√£o encontrada. Configure a vari√°vel de ambiente.')

    def __enter__(self):
        """Context manager para gerenciar arquivos tempor√°rios."""
        self.temp_dir = tempfile.mkdtemp()
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        """Limpa arquivos tempor√°rios."""
        if self.temp_dir and os.path.exists(self.temp_dir):
            import shutil

            shutil.rmtree(self.temp_dir)
            logger.info(f'Arquivos tempor√°rios removidos: {self.temp_dir}')

    def download_audio(self, url: str) -> Dict[str, Any]:
        """
        Baixa o √°udio de um v√≠deo do YouTube.

        Args:
            url: URL do v√≠deo do YouTube

        Returns:
            Dict com informa√ß√µes do v√≠deo e caminho do arquivo de √°udio
        """
        logger.info(f'Baixando √°udio de: {url}')

        # Configura√ß√£o do yt-dlp usando configura√ß√µes centralizadas
        ydl_opts = {
            'format': YT_DLP_FORMAT,
            'outtmpl': os.path.join(self.temp_dir, '%(title)s.%(ext)s'),
            'postprocessors': [
                {
                    'key': 'FFmpegExtractAudio',
                    'preferredcodec': AUDIO_FORMAT,
                    'preferredquality': AUDIO_QUALITY,
                }
            ],
            'quiet': YT_DLP_QUIET,
            'no_warnings': YT_DLP_NO_WARNINGS,
        }

        try:
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                # Extrai informa√ß√µes do v√≠deo
                info = ydl.extract_info(url, download=False)
                video_info = {
                    'title': info.get('title', 'V√≠deo sem t√≠tulo'),
                    'duration': info.get('duration', 0),
                    'uploader': info.get('uploader', 'Desconhecido'),
                    'upload_date': info.get('upload_date', ''),
                    'description': info.get('description', ''),
                    'url': url,
                }

                # Baixa o √°udio
                ydl.download([url])

                # Encontra o arquivo de √°udio baixado
                audio_files = list(Path(self.temp_dir).glob('*.mp3'))
                if not audio_files:
                    raise FileNotFoundError('Arquivo de √°udio n√£o encontrado ap√≥s download')

                video_info['audio_path'] = str(audio_files[0])
                logger.info(f'√Åudio baixado com sucesso: {video_info["title"]}')

                return video_info

        except Exception as e:
            logger.error(f'Erro ao baixar √°udio de {url}: {str(e)}')
            raise

    def segment_audio(self, audio_path: str) -> List[str]:
        """
        Segmenta um arquivo de √°udio em partes menores usando FFmpeg.

        Args:
            audio_path: Caminho para o arquivo de √°udio original

        Returns:
            Lista com caminhos dos segmentos de √°udio
        """
        import subprocess

        logger.info(f'Segmentando √°udio: {audio_path}')

        # Obt√©m a dura√ß√£o do √°udio
        duration_cmd = ['ffprobe', '-v', 'quiet', '-show_entries', 'format=duration', '-of', 'csv=p=0', audio_path]

        try:
            duration_result = subprocess.run(duration_cmd, capture_output=True, text=True, check=True)
            duration_seconds = float(duration_result.stdout.strip())
            logger.info(f'Dura√ß√£o do √°udio: {duration_seconds:.2f} segundos')
        except subprocess.CalledProcessError as e:
            logger.error(f'Erro ao obter dura√ß√£o do √°udio: {e}')
            raise

        # Calcula o n√∫mero de segmentos necess√°rios
        segment_duration = AUDIO_SEGMENT_DURATION_MINUTES * 60
        num_segments = int(duration_seconds / segment_duration) + 1

        if num_segments == 1:
            logger.info('√Åudio n√£o precisa ser segmentado')
            return [audio_path]

        logger.info(f'Segmentando em {num_segments} partes de {AUDIO_SEGMENT_DURATION_MINUTES} minutos cada')

        segments = []
        base_name = Path(audio_path).stem

        for i in range(num_segments):
            start_time = i * segment_duration
            # Adiciona sobreposi√ß√£o exceto no primeiro segmento
            if i > 0:
                start_time -= AUDIO_SEGMENT_OVERLAP_SECONDS

            segment_path = os.path.join(self.temp_dir, f'{base_name}_segment_{i + 1:02d}.mp3')

            # Comando FFmpeg para extrair segmento
            ffmpeg_cmd = [
                'ffmpeg',
                '-i',
                audio_path,
                '-ss',
                str(start_time),
                '-t',
                str(segment_duration + AUDIO_SEGMENT_OVERLAP_SECONDS),
                '-acodec',
                'copy',
                '-y',
                segment_path,
            ]

            try:
                subprocess.run(ffmpeg_cmd, capture_output=True, check=True)
                segments.append(segment_path)
                logger.info(f'Segmento {i + 1}/{num_segments} criado: {segment_path}')
            except subprocess.CalledProcessError as e:
                logger.error(f'Erro ao criar segmento {i + 1}: {e}')
                raise

        return segments

    def transcribe_audio_segments(self, segments: List[str]) -> Dict[str, Any]:
        """
        Transcreve m√∫ltiplos segmentos de √°udio e combina os resultados.

        Args:
            segments: Lista de caminhos para segmentos de √°udio

        Returns:
            Dict com transcri√ß√£o combinada
        """
        logger.info(f'Transcrevendo {len(segments)} segmentos de √°udio')

        all_transcriptions = []
        total_duration = 0

        for i, segment_path in enumerate(segments, 1):
            logger.info(f'Transcrevendo segmento {i}/{len(segments)}')

            try:
                with open(segment_path, 'rb') as audio_file:
                    # Calcula o custo estimado
                    file_size_mb = os.path.getsize(segment_path) / (1024 * 1024)
                    estimated_duration_minutes = file_size_mb / AUDIO_SIZE_DURATION_RATIO
                    estimated_cost = estimated_duration_minutes * OPENAI_WHISPER_COST_PER_MINUTE
                    self.total_cost_usd += estimated_cost

                    logger.info(f'Segmento {i}: {file_size_mb:.2f}MB - Custo estimado: ${estimated_cost:.4f} USD')

                    # Chama a API da OpenAI
                    response = openai.audio.transcriptions.create(
                        model=OPENAI_WHISPER_MODEL,
                        file=audio_file,
                        response_format='verbose_json',
                    )

                    all_transcriptions.append(response.text)
                    total_duration += response.duration if hasattr(response, 'duration') else 0

                    logger.info(f'Segmento {i} transcrito com sucesso')

            except Exception as e:
                logger.error(f'Erro na transcri√ß√£o do segmento {i}: {str(e)}')
                raise

        # Combina todas as transcri√ß√µes
        combined_text = ' '.join(all_transcriptions)

        logger.info('Todos os segmentos transcritos e combinados com sucesso')

        return {'text': combined_text, 'duration': total_duration, 'segments_count': len(segments)}

    def check_audio_size_and_transcribe(self, audio_path: str) -> Dict[str, Any]:
        """
        Verifica o tamanho do √°udio e decide se precisa segmentar antes de transcrever.

        Args:
            audio_path: Caminho para o arquivo de √°udio

        Returns:
            Dict com a transcri√ß√£o
        """
        file_size_mb = os.path.getsize(audio_path) / (1024 * 1024)
        logger.info(f'Tamanho do arquivo de √°udio: {file_size_mb:.2f}MB')

        if file_size_mb > MAX_AUDIO_FILE_SIZE_MB:
            logger.warning(f'Arquivo muito grande ({file_size_mb:.2f}MB > {MAX_AUDIO_FILE_SIZE_MB}MB)')
            logger.info('Segmentando √°udio antes da transcri√ß√£o...')

            segments = self.segment_audio(audio_path)
            return self.transcribe_audio_segments(segments)
        else:
            logger.info('Arquivo dentro do limite, transcrevendo diretamente')
            return self.transcribe_audio(audio_path)

    def transcribe_audio(self, audio_path: str) -> Dict[str, Any]:
        """
        Transcreve o √°udio usando a API da OpenAI.

        Args:
            audio_path: Caminho para o arquivo de √°udio

        Returns:
            Dict com a transcri√ß√£o
        """
        logger.info(f'Transcrevendo √°udio: {audio_path}')

        try:
            with open(audio_path, 'rb') as audio_file:
                # Calcula o custo estimado usando configura√ß√µes centralizadas
                file_size_mb = os.path.getsize(audio_path) / (1024 * 1024)
                estimated_duration_minutes = file_size_mb / AUDIO_SIZE_DURATION_RATIO
                estimated_cost = estimated_duration_minutes * OPENAI_WHISPER_COST_PER_MINUTE
                self.total_cost_usd += estimated_cost

                logger.info(f'Enviando para transcri√ß√£o (custo estimado: ${estimated_cost:.4f} USD)')

                # Chama a API da OpenAI usando configura√ß√µes centralizadas
                response = openai.audio.transcriptions.create(
                    model=OPENAI_WHISPER_MODEL,
                    file=audio_file,
                    response_format='verbose_json',
                )

                logger.info('Transcri√ß√£o conclu√≠da com sucesso')
                return {
                    'text': response.text,
                    'duration': response.duration if hasattr(response, 'duration') else 0,
                }

        except Exception as e:
            logger.error(f'Erro na transcri√ß√£o: {str(e)}')
            raise

    def save_transcription(self, transcription: Dict[str, Any], video_info: Dict[str, Any]) -> str:
        """
        Salva a transcri√ß√£o em arquivo JSON para processamento posterior.

        Args:
            transcription: Dados da transcri√ß√£o
            video_info: Informa√ß√µes do v√≠deo

        Returns:
            Caminho do arquivo de transcri√ß√£o salvo
        """
        logger.info('Salvando transcri√ß√£o em arquivo...')

        # Converte a transcri√ß√£o para formato serializ√°vel
        serializable_transcription = {'text': transcription['text'], 'duration': transcription['duration']}

        # Prepara dados para salvar
        transcription_data = {
            'video_info': video_info,
            'transcription': serializable_transcription,
            'generated_at': datetime.now().isoformat(),
        }

        # Nome do arquivo baseado no t√≠tulo do v√≠deo
        safe_title = ''.join(c for c in video_info['title'] if c.isalnum() or c in (' ', '-', '_')).rstrip()
        filename = f'transcricao_{safe_title[:30]}.json'
        filepath = self.output_dir / filename

        # Salva o arquivo
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(transcription_data, f, ensure_ascii=False, indent=2)

        logger.info(f'Transcri√ß√£o salva em: {filepath}')
        return str(filepath)

    def generate_ebook_content(self, transcription_file: str) -> Dict[str, Any]:
        """
        Processa a transcri√ß√£o usando OpenAI para gerar conte√∫do estruturado do ebook.

        Args:
            transcription_file: Caminho do arquivo de transcri√ß√£o

        Returns:
            Dict com conte√∫do estruturado do ebook
        """
        logger.info('Processando transcri√ß√£o com OpenAI para gerar conte√∫do do ebook...')

        # Carrega a transcri√ß√£o
        with open(transcription_file, 'r', encoding='utf-8') as f:
            data = json.load(f)

        transcription_text = data['transcription']['text']
        video_info = data['video_info']

        # Prompt avan√ßado para estruturar o conte√∫do do ebook com m√°ximo detalhamento
        system_prompt = SYSTEM_PROMPT_EBOOK
        user_prompt = get_user_prompt_ebook(video_info, transcription_text, self._format_duration)

        try:
            # Estima tokens para calcular custo
            estimated_tokens = len(transcription_text) // 3  # Estimativa aproximada
            estimated_cost = (estimated_tokens / 1000) * OPENAI_GPT_COST_PER_1K_TOKENS
            self.total_cost_usd += estimated_cost

            logger.info(f'Enviando para processamento GPT (custo estimado: ${estimated_cost:.4f} USD)')

            # Tenta processar com retry em caso de falha usando configura√ß√µes centralizadas
            ebook_content = None

            for attempt in range(MAX_API_RETRIES + 1):
                try:
                    logger.info(f'Tentativa {attempt + 1}/{MAX_API_RETRIES + 1} de processamento GPT')

                    # Chama a API da OpenAI usando configura√ß√µes centralizadas
                    response = openai.chat.completions.create(
                        model=OPENAI_GPT_MODEL,
                        messages=[
                            {'role': 'system', 'content': system_prompt},
                            {'role': 'user', 'content': user_prompt},
                        ],
                        temperature=OPENAI_GPT_TEMPERATURE,
                        max_tokens=OPENAI_GPT_MAX_TOKENS,
                    )

                    break  # Sai do loop se a chamada foi bem-sucedida

                except Exception as api_error:
                    logger.warning(f'Tentativa {attempt + 1} falhou: {api_error}')
                    if attempt == MAX_API_RETRIES:
                        raise api_error
                    logger.info(f'Tentando novamente em {RETRY_DELAY} segundos...')
                    import time

                    time.sleep(RETRY_DELAY)

            # Extrai o conte√∫do da resposta
            content = response.choices[0].message.content

            # Fun√ß√£o para limpar e corrigir JSON malformado
            def clean_json_content(json_str: str) -> str:
                """Limpa e corrige problemas comuns em JSON gerado por IA."""
                import re

                # Remove markdown code blocks se existirem
                json_str = re.sub(r'```json\s*', '', json_str)
                json_str = re.sub(r'```\s*$', '', json_str)

                # Remove texto antes e depois do JSON
                json_match = re.search(r'\{.*\}', json_str, re.DOTALL)
                if json_match:
                    json_str = json_match.group()

                # Corrige aspas simples para duplas (problema comum)
                json_str = re.sub(r"'([^']*)':", r'"\1":', json_str)

                # Corrige trailing commas
                json_str = re.sub(r',(\s*[}\]])', r'\1', json_str)

                # Corrige quebras de linha dentro de strings
                json_str = re.sub(r'"\s*\n\s*([^"]*)\s*\n\s*"', r'"\1"', json_str)

                return json_str

            # Tenta fazer parse do JSON com m√∫ltiplas estrat√©gias
            ebook_content = None
            original_content = content

            # Estrat√©gia 1: Parse direto
            try:
                ebook_content = json.loads(content)
                logger.info('JSON parseado com sucesso na primeira tentativa')
            except json.JSONDecodeError as e:
                logger.warning(f'Primeira tentativa de parse falhou: {e}')

                # Estrat√©gia 2: Limpar e tentar novamente
                try:
                    cleaned_content = clean_json_content(content)
                    ebook_content = json.loads(cleaned_content)
                    logger.info('JSON parseado com sucesso ap√≥s limpeza')
                except json.JSONDecodeError as e:
                    logger.warning(f'Segunda tentativa de parse falhou: {e}')

                    # Estrat√©gia 3: Tentar corrigir caracteres problem√°ticos
                    try:
                        # Remove caracteres de controle
                        import unicodedata

                        cleaned_content = ''.join(
                            ch for ch in content if unicodedata.category(ch)[0] != 'C' or ch in '\n\r\t'
                        )
                        cleaned_content = clean_json_content(cleaned_content)
                        ebook_content = json.loads(cleaned_content)
                        logger.info('JSON parseado com sucesso ap√≥s limpeza de caracteres')
                    except json.JSONDecodeError as e:
                        logger.error(f'Todas as tentativas de parse falharam: {e}')

                        # Salva o conte√∫do problem√°tico para debug usando configura√ß√µes centralizadas
                        debug_file = self.output_dir / DEBUG_OPENAI_RESPONSE_FILE
                        with open(debug_file, 'w', encoding='utf-8') as f:
                            f.write(f'Resposta original da OpenAI:\n{original_content}\n\n')
                            f.write(f'Erro de parse: {e}\n')

                        logger.error(f'Resposta problem√°tica salva em: {debug_file}')
                        raise ValueError(
                            f'N√£o foi poss√≠vel fazer parse do JSON retornado pela OpenAI. Erro: {e}\nResposta salva em: {debug_file}'
                        )

            if ebook_content is None:
                raise ValueError('Falha cr√≠tica no processamento do JSON da OpenAI')

            # Valida a estrutura do JSON
            def validate_ebook_structure(data: dict) -> bool:
                """Valida se o JSON tem a estrutura esperada do ebook."""
                required_fields = ['title', 'subtitle', 'author', 'description', 'chapters', 'conclusion', 'key_points']

                for field in required_fields:
                    if field not in data:
                        logger.warning(f'Campo obrigat√≥rio ausente: {field}')
                        return False

                if not isinstance(data['chapters'], list) or len(data['chapters']) == 0:
                    logger.warning('Campo chapters deve ser uma lista n√£o vazia')
                    return False

                for i, chapter in enumerate(data['chapters']):
                    if not isinstance(chapter, dict):
                        logger.warning(f'Cap√≠tulo {i} deve ser um objeto')
                        return False

                    chapter_required = ['title', 'content']
                    for field in chapter_required:
                        if field not in chapter:
                            logger.warning(f'Campo obrigat√≥rio ausente no cap√≠tulo {i}: {field}')
                            return False

                return True

            # Valida a estrutura
            if not validate_ebook_structure(ebook_content):
                logger.error('Estrutura do JSON inv√°lida')
                # Salva para debug mesmo assim usando configura√ß√µes centralizadas
                debug_file = self.output_dir / DEBUG_INVALID_STRUCTURE_FILE
                with open(debug_file, 'w', encoding='utf-8') as f:
                    json.dump(ebook_content, f, ensure_ascii=False, indent=2)
                logger.error(f'JSON com estrutura inv√°lida salvo em: {debug_file}')
                raise ValueError(f'JSON retornado pela OpenAI tem estrutura inv√°lida. Arquivo salvo em: {debug_file}')

            logger.info('Estrutura do JSON validada com sucesso')

            # Salva o conte√∫do estruturado
            safe_title = ''.join(c for c in video_info['title'] if c.isalnum() or c in (' ', '-', '_')).rstrip()
            content_filename = f'ebook_content_{safe_title[:30]}.json'
            content_filepath = self.output_dir / content_filename

            with open(content_filepath, 'w', encoding='utf-8') as f:
                json.dump(ebook_content, f, ensure_ascii=False, indent=2)

            logger.info(f'Conte√∫do estruturado salvo em: {content_filepath}')
            logger.info('Processamento com OpenAI conclu√≠do com sucesso')

            return ebook_content

        except Exception as e:
            logger.error(f'Erro no processamento com OpenAI: {str(e)}')
            raise

    def _process_markdown(self, text: str) -> str:
        """
        Processa markdown simples para HTML (negrito, it√°lico, listas).

        Args:
            text: Texto com markdown simples

        Returns:
            Texto com HTML
        """
        if not text:
            return text

        import re

        # Converte **texto** para <strong>texto</strong>
        text = re.sub(r'\*\*(.*?)\*\*', r'<strong>\1</strong>', text)

        # Converte *texto* para <em>texto</em> (mas n√£o se for in√≠cio de lista)
        text = re.sub(r'(?<!^)\*([^*\n]+?)\*', r'<em>\1</em>', text, flags=re.MULTILINE)

        # Processa listas simples (linhas que come√ßam com - ou *)
        lines = text.split('\n')
        processed_lines = []
        in_list = False

        for line in lines:
            stripped = line.strip()
            if stripped.startswith('- ') or stripped.startswith('* '):
                if not in_list:
                    processed_lines.append('<ul>')
                    in_list = True
                item_text = stripped[2:].strip()
                processed_lines.append(f'<li>{item_text}</li>')
            else:
                if in_list:
                    processed_lines.append('</ul>')
                    in_list = False
                processed_lines.append(line)

        if in_list:
            processed_lines.append('</ul>')

        return '\n'.join(processed_lines)

    def generate_html_content(self, ebook_content: Dict[str, Any], video_info: Dict[str, Any]) -> str:
        """
        Gera o conte√∫do HTML do ebook usando o conte√∫do estruturado.

        Args:
            ebook_content: Conte√∫do estruturado do ebook
            video_info: Informa√ß√µes do v√≠deo original

        Returns:
            String com o HTML do ebook
        """
        logger.info('Gerando conte√∫do HTML estruturado...')

        # Carrega o template HTML usando configura√ß√µes centralizadas
        env = Environment(loader=FileSystemLoader(TEMPLATE_DIR))

        # Adiciona filtro personalizado para processar markdown
        env.filters['markdown'] = self._process_markdown

        template = env.get_template(HTML_TEMPLATE_NAME)

        # Prepara dados para o template
        template_data = {
            'ebook_title': ebook_content.get('title', video_info['title']),
            'ebook_subtitle': ebook_content.get('subtitle', 'Ebook gerado automaticamente'),
            'ebook_author': ebook_content.get('author', video_info['uploader']),
            'ebook_description': ebook_content.get('description', ''),
            'chapters': ebook_content.get('chapters', []),
            'conclusion': ebook_content.get('conclusion', ''),
            'key_points': ebook_content.get('key_points', []),
            'video_info': {**video_info, 'formatted_duration': self._format_duration(video_info['duration'])},
            'generation_date': datetime.now().strftime('%d/%m/%Y √†s %H:%M'),
        }

        # Renderiza o template
        html_content = template.render(**template_data)

        return html_content

    def _format_duration(self, seconds: int) -> str:
        """Formata dura√ß√£o em segundos para formato leg√≠vel."""
        if not seconds:
            return 'Desconhecido'

        hours = seconds // 3600
        minutes = (seconds % 3600) // 60
        seconds = seconds % 60

        if hours > 0:
            return f'{hours}h {minutes}m {seconds}s'
        elif minutes > 0:
            return f'{minutes}m {seconds}s'
        else:
            return f'{seconds}s'

    def _format_cost(self, usd: float) -> str:
        """Formata custo em d√≥lares para formato leg√≠vel."""
        brl = usd * USD_TO_BRL
        return f'${usd:.4f} USD ({brl:.2f} BRL)'

    def generate_css(self) -> str:
        """
        Carrega o CSS do arquivo template usando configura√ß√µes centralizadas.

        Returns:
            String com o CSS
        """
        css_path = get_template_dir() / CSS_TEMPLATE_NAME

        if not css_path.exists():
            logger.error(f'Arquivo CSS n√£o encontrado: {css_path}')
            raise FileNotFoundError(f'Template CSS n√£o encontrado: {css_path}')

        with open(css_path, 'r', encoding='utf-8') as f:
            css_content = f.read()

        return css_content

    def generate_pdf(self, html_content: str, css_content: str, output_filename: str) -> str:
        """
        Gera o PDF usando WeasyPrint com base_url correto para templates.

        Args:
            html_content: Conte√∫do HTML
            css_content: Conte√∫do CSS
            output_filename: Nome do arquivo de sa√≠da

        Returns:
            Caminho do arquivo PDF gerado
        """
        logger.info('Gerando PDF...')

        try:
            # Define o base_url para o diret√≥rio de templates usando configura√ß√µes centralizadas
            template_dir = get_template_dir().absolute()
            base_url = template_dir.as_uri() + '/'

            # Cria objetos HTML e CSS com base_url correto
            html_doc = HTML(string=html_content, base_url=base_url)
            css_doc = CSS(string=css_content, base_url=base_url)

            # Gera o PDF
            output_path = self.output_dir / output_filename
            html_doc.write_pdf(output_path, stylesheets=[css_doc])

            logger.info(f'PDF gerado com sucesso: {output_path}')
            return str(output_path)

        except Exception as e:
            logger.error(f'Erro ao gerar PDF: {str(e)}')
            raise

    def display_cost_summary(self):
        """Exibe o resumo de custos da API OpenAI."""
        cost_brl = self.total_cost_usd * USD_TO_BRL

        print('\n' + '=' * 50)
        print('RESUMO DE CUSTOS DA API OPENAI')
        print('=' * 50)
        print(f'Custo total (USD): ${self.total_cost_usd:.4f}')
        print(f'Custo total (BRL): R$ {cost_brl:.2f}')
        print(f'Cota√ß√£o utilizada: 1 USD = R$ {USD_TO_BRL}')
        print('=' * 50)

    def process_video(self, url: str, output_filename: Optional[str] = None) -> str:
        """
        Processa um v√≠deo do YouTube seguindo o novo fluxo:
        1. Download do √°udio
        2. Transcri√ß√£o com OpenAI Whisper
        3. Salvamento da transcri√ß√£o
        4. Processamento com OpenAI GPT para gerar conte√∫do estruturado
        5. Gera√ß√£o do ebook com template

        Args:
            url: URL do v√≠deo do YouTube
            output_filename: Nome do arquivo de sa√≠da (opcional)

        Returns:
            Caminho do arquivo PDF gerado
        """
        logger.info(f'Iniciando processamento do v√≠deo: {url}')

        try:
            # Etapa 1: Download do √°udio
            logger.info('Etapa 1/5: Download do √°udio')
            video_info = self.download_audio(url)

            # Etapa 2: Transcri√ß√£o (com verifica√ß√£o de tamanho autom√°tica)
            logger.info('Etapa 2/5: Transcri√ß√£o com OpenAI Whisper')
            transcription = self.check_audio_size_and_transcribe(video_info['audio_path'])

            # Etapa 3: Salvamento da transcri√ß√£o
            logger.info('Etapa 3/5: Salvamento da transcri√ß√£o')
            transcription_file = self.save_transcription(transcription, video_info)

            # Etapa 4: Processamento com OpenAI para gerar conte√∫do estruturado
            logger.info('Etapa 4/5: Processamento com OpenAI GPT para estruturar conte√∫do')
            ebook_content = self.generate_ebook_content(transcription_file)

            # Etapa 5: Gera√ß√£o do ebook
            logger.info('Etapa 5/5: Gera√ß√£o do ebook')

            # Gera o nome do arquivo se n√£o fornecido
            if not output_filename:
                safe_title = ''.join(c for c in video_info['title'] if c.isalnum() or c in (' ', '-', '_')).rstrip()
                output_filename = f'{safe_title[:50]}.pdf'

            # Garante que o arquivo tenha extens√£o .pdf
            if not output_filename.endswith('.pdf'):
                output_filename += '.pdf'

            # Gera HTML e CSS
            html_content = self.generate_html_content(ebook_content, video_info)
            css_content = self.generate_css()

            # Gera PDF
            pdf_path = self.generate_pdf(html_content, css_content, output_filename)

            # Exibe resumo de custos
            self.display_cost_summary()

            logger.info('Processamento conclu√≠do com sucesso!')
            return pdf_path

        except Exception as e:
            logger.error(f'Erro durante o processamento: {str(e)}')
            raise


def main():
    """Fun√ß√£o principal do script."""
    # URL de teste conforme especificado no PRD
    test_url = DEFAULT_TEST_URL

    print('Gerador de Ebook a partir de V√≠deos do YouTube')
    print('=' * 50)
    print('Novo fluxo de processamento:')
    print('1. Download do √°udio')
    print('2. Transcri√ß√£o com OpenAI Whisper')
    print('3. Salvamento da transcri√ß√£o')
    print('4. Processamento com OpenAI GPT para estruturar conte√∫do')
    print('5. Gera√ß√£o do ebook com template')
    print('=' * 50)

    # Verifica se a API key est√° configurada
    if not os.getenv('OPENAI_API_KEY'):
        print('ERRO: Configure a vari√°vel de ambiente OPENAI_API_KEY')
        print("Exemplo: export OPENAI_API_KEY='sua-api-key-aqui'")
        return 1

    try:
        print(f'Processando v√≠deo de teste: {test_url}')

        # Processa o v√≠deo
        with YouTubeEbookGenerator() as generator:
            pdf_path = generator.process_video(test_url)

        print('\n‚úÖ Ebook gerado com sucesso!')
        print(f'üìÅ Arquivo salvo em: {pdf_path}')
        print(f'üìä Tamanho do arquivo: {os.path.getsize(pdf_path) / 1024 / 1024:.2f} MB')

        return 0

    except Exception as e:
        logger.error(f'Erro durante a execu√ß√£o: {str(e)}')
        print(f'\n‚ùå Erro: {str(e)}')
        return 1


def app():
    """Ponto de entrada para o script como aplica√ß√£o."""
    sys.exit(main())


if __name__ == '__main__':
    app()
